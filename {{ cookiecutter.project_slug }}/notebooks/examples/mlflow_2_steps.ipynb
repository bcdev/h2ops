{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "350435f4-6f17-4a62-8c3f-11b9e0d08e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a6fd82-0246-466d-b20f-9d76751bdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://127.0.0.1:9000\",\n",
    "    aws_access_key_id=\"minio\",\n",
    "    aws_secret_access_key=\"minio123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3921f337-d29a-4363-abe2-1531c8026b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:5000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.getenv(\"J_MLFLOW_SERVER_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad33add-5079-4800-ad35-8dad3a29e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name):\n",
    "    \"\"\"\n",
    "    Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "    This function checks if an experiment with the given name exists within MLflow.\n",
    "    If it does, the function returns its ID. If not, it creates a new experiment\n",
    "    with the provided name and returns its ID.\n",
    "\n",
    "    Taken from mlflow.org\n",
    "\n",
    "    Parameters:\n",
    "    - experiment_name (str): Name of the MLflow experiment.\n",
    "\n",
    "    Returns:\n",
    "    - str: ID of the existing or newly created MLflow experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5dc76c-83eb-45f6-8201-c1e75f486059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_data_path(\n",
    "        s3_client: boto3.client,\n",
    "        bucket_name: str,\n",
    "        base_folder: str = 'preprocessing'\n",
    ") -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Find the latest timestamp folder and NPZ file in the specified bucket/folder\n",
    "    Returns tuple of (full_path, filename)\n",
    "    \"\"\"\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=f\"{base_folder}/\",\n",
    "        Delimiter='/'\n",
    "    )\n",
    "\n",
    "    timestamps = []\n",
    "    for prefix in response.get('CommonPrefixes', []):\n",
    "        folder_name = prefix['Prefix'].strip('/')\n",
    "        try:\n",
    "            timestamp = folder_name.replace(f\"{base_folder}/\", '')\n",
    "            timestamps.append(timestamp)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    if not timestamps:\n",
    "        raise ValueError(\"No timestamp folders found\")\n",
    "\n",
    "    latest_timestamp = sorted(timestamps)[-1]\n",
    "    latest_folder = f\"{base_folder}/{latest_timestamp}\"\n",
    "\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=latest_folder\n",
    "    )\n",
    "\n",
    "    npz_files = [\n",
    "        obj['Key'] for obj in response.get('Contents', [])\n",
    "        if obj['Key'].endswith('.npz')\n",
    "    ]\n",
    "\n",
    "    if not npz_files:\n",
    "        raise ValueError(f\"No NPZ files found in {latest_folder}\")\n",
    "\n",
    "    latest_file = npz_files[0]\n",
    "    return latest_file, latest_file.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a22f2f8-268f-4725-b84c-dd17713313f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_store():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "    X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "    local_path = f\"/tmp/mnist_processed_{timestamp}.npz\"\n",
    "    np.savez_compressed(local_path,\n",
    "                        X_train=X_train, y_train=y_train,\n",
    "                        X_test=X_test, y_test=y_test)\n",
    "\n",
    "    bucket_name = \"mnist-data\"\n",
    "    object_path = f\"preprocessing/{timestamp}/mnist_processed.npz\"\n",
    "\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket_name)\n",
    "    except:\n",
    "        print(f\"Bucket: {bucket_name} does not exist, creating one now!\")\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "    s3.upload_file(local_path, bucket_name, object_path)\n",
    "\n",
    "    os.remove(local_path)\n",
    "    print(f\"Preprocessed data stored to MinIO: {object_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2adc638e-7ad5-4774-99db-482213c59af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "    \n",
    "    bucket_name=\"mnist-data\"\n",
    "    base_folder=\"preprocessing\"\n",
    "    s3_path, filename = get_latest_data_path(s3, bucket_name=bucket_name,\n",
    "                                             base_folder=base_folder)\n",
    "    local_path = \"/tmp\"\n",
    "    local_file = f\"{local_path}/{filename}\"\n",
    "    s3.download_file(bucket_name, s3_path, local_file)\n",
    "\n",
    "    data = np.load(local_file)\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "    X_test, y_test = data['X_test'], data['y_test']\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    mlflow.set_tracking_uri(os.getenv(\"J_MLFLOW_SERVER_URI\"))\n",
    "    experiment_id=get_or_create_experiment(\"MNIST_Hyperparameter_Search_autolog\")\n",
    "    mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    HYPERPARAM_GRID = {\n",
    "        'epochs': [1, 2]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*HYPERPARAM_GRID.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in\n",
    "                          itertools.product(*values)]\n",
    "    \n",
    "    mlflow.autolog()\n",
    "    with mlflow.start_run(run_name=\"mnist-hyperparameter-tuning-parent\"):\n",
    "        for params in param_combinations:\n",
    "            with mlflow.start_run(nested=True):\n",
    "                model = keras.Sequential([\n",
    "                    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "                    keras.layers.MaxPooling2D((2, 2)),\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(128, activation='relu'),\n",
    "                    keras.layers.Dense(10, activation='softmax')\n",
    "                ])\n",
    "        \n",
    "                optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                history = model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    validation_data=(X_test, y_test),\n",
    "                )\n",
    "    \n",
    "                val_acc = history.history['val_accuracy'][-1]\n",
    "                train_acc = history.history['accuracy'][-1]\n",
    "    \n",
    "                if val_acc > best_accuracy:\n",
    "                    best_accuracy = val_acc\n",
    "                    best_model = model\n",
    "                    best_params = params\n",
    "                    \n",
    "            if best_model is not None:\n",
    "                artifact_path = \"mnist_model_autolog\"\n",
    "                mlflow.tensorflow.log_model(model, artifact_path)\n",
    "        \n",
    "                model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "                print(\"Model stored at \", model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9ef840-facd-432a-9ca6-92756fa03929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data stored to MinIO: preprocessing/20250205-103140/mnist_processed.npz\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec76cbc7-7d81-4cc9-bd8f-08816a99b0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:9000'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = os.getenv(\"J_MLFLOW_S3_ENDPOINT_URL\")\n",
    "os.getenv(\"MLFLOW_S3_ENDPOINT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e2c5991-6c3d-4649-833c-91289db9e983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/05 10:48:11 INFO mlflow.bedrock: Enabled auto-tracing for Bedrock. Note that MLflow can only trace boto3 service clients that are created after this call. If you have already created one, please recreate the client by calling `boto3.client`.\n",
      "2025/02/05 10:48:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for boto3.\n",
      "2025/02/05 10:48:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/02/05 10:48:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/02/05 10:48:11 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "/home/yogesh/miniforge3/envs/mlops/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1870/1875\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9153 - loss: 0.2849 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.9154 - loss: 0.2845 - val_accuracy: 0.9798 - val_loss: 0.0609\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7afd279365c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7afd279365c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/05 10:48:31 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沛 View run overjoyed-turtle-772 at: http://localhost:5000/#/experiments/2/runs/d5aee92cb6cc46dab7679df2378d4679\n",
      "洫ｪ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/05 10:48:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stored at  s3://mlflow/2/c8f6b2065d824ccf96f9aa3bdf8098bf/artifacts/mnist_model_autolog\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1869/1875\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9134 - loss: 0.2888 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9135 - loss: 0.2883 - val_accuracy: 0.9803 - val_loss: 0.0628\n",
      "Epoch 2/2\n",
      "\u001b[1m1869/1875\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[37m笏―u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9843 - loss: 0.0508 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 8ms/step - accuracy: 0.9843 - loss: 0.0508 - val_accuracy: 0.9846 - val_loss: 0.0462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/05 10:49:10 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沛 View run learned-foal-225 at: http://localhost:5000/#/experiments/2/runs/a20e2f61b9df46d5a5ef83cf9c5afc54\n",
      "洫ｪ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/05 10:49:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stored at  s3://mlflow/2/c8f6b2065d824ccf96f9aa3bdf8098bf/artifacts/mnist_model_autolog\n",
      "沛 View run mnist-hyperparameter-tuning-parent at: http://localhost:5000/#/experiments/2/runs/c8f6b2065d824ccf96f9aa3bdf8098bf\n",
      "洫ｪ View experiment at: http://localhost:5000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "train_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943279e4-f266-4eea-8cc0-b0a47d807e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
