{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1405501-a54f-4b11-96e6-215ac61f616a",
   "metadata": {},
   "source": [
    "# Introduction to MLflow APIs for Experiment Tracking\n",
    "\n",
    "MLflow is an openâ€source platform designed to manage the end-to-end machine learning lifecycle. In this section, we introduce several key MLflow APIs that you can use to set up your experiment tracking, log runs and models, and manage your model registry. For more details, refer to the official [MLflow documentation](mlflow.org)\n",
    "\n",
    "\n",
    "This notebook provides a starting point on how to use MLFLow for logging your experiements and artifacts.\n",
    "\n",
    "Before starting this notebook, make sure the services are running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4a766-48a2-49ca-96b4-98b55ebdb1fe",
   "metadata": {},
   "source": [
    "## Setting Up the Tracking Environment\n",
    "\n",
    "Before you begin logging experiments and models, you must configure the tracking server. MLflow uses a tracking URI to know where to store experiment data such as metrics, parameters, and artifacts.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.set_tracking_uri(uri)\n",
    "    \n",
    "    What it does: Configures the tracking serverâ€™s URI (this can be a local directory, a remote HTTP endpoint, or a database URI).\n",
    "    When to use: Call this at the very start of your script to ensure all logs go to the correct destination.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.get_tracking_uri()\n",
    "\n",
    "    What it does: Retrieves the currently configured tracking URI, which is useful for debugging or verifying your setup.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a8776-1f44-485f-b664-a94f6831d65b",
   "metadata": {},
   "source": [
    "## Managing Experiments\n",
    "\n",
    "Experiments group related runs, making it easier to organize and compare different model training sessions.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "    What it does: Explicitly creates a new experiment and returns its unique ID.\n",
    "    When to use: When you want to programmatically create an experiment without necessarily switching to it immediately.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    What it does: Sets the active experiment for your run. If the experiment doesnâ€™t already exist, it will be created automatically.\n",
    "    When to use: At the beginning of your experiment code to ensure all subsequent runs are recorded under the correct experiment.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70990c0-27ad-4644-99c9-d1ce995e8a43",
   "metadata": {},
   "source": [
    "## Logging Runs and Enabling Auto-Logging\n",
    "\n",
    "Once your tracking environment and experiment are set, you can start logging runs.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.start_run()\n",
    "    \n",
    "    What it does: Starts a new MLflow run and returns an ActiveRun object. It can be used as a context manager so that the run is automatically ended when the block finishes.\n",
    "    When to use: Wrap your training (or any experimental) code within a with mlflow.start_run(): block to log parameters, metrics, and artifacts.\n",
    "    Note: You can use one start_run inside another which forms a parent-child relationship between them leading to grouped experiments by setting `nested=True` inside the start_run of the child (useful for hyperparameter-tuning)\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.log_param(key, value)\n",
    "    \n",
    "    Log a single parameter as a key-value pair. Parameters are typically hyperparameters or configuration values.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.log_params(params_dict)\n",
    "    \n",
    "    Log multiple parameters at once by passing a dictionary. Example:\n",
    "    \n",
    "    params = {\"learning_rate\": 0.01, \"num_layers\": 3, \"batch_size\": 32}\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.log_param(key, value)\n",
    "    \n",
    "    Log a single parameter. Example:\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(key=\"data_source\", value=s3_path)\n",
    "\n",
    "\n",
    "======================================================\n",
    "\n",
    "\n",
    "    mlflow.autolog()\n",
    "\n",
    "    What it does: Automatically logs parameters, metrics, and models from supported machine learning libraries (such as scikit-learn, TensorFlow, PyTorch, etc.).\n",
    "    When to use: Use this at the beginning of your training code to minimize manual logging.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.<framework>.log_model()\n",
    "\n",
    "    What it does: Logs a trained model as an artifact. Replace <framework> with the specific module (e.g., sklearn, tensorflow, or pytorch).\n",
    "    When to use: After youâ€™ve trained your model, call this function to save the model so that it can later be served or compared.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e13c3-8a4e-462e-9f53-ebe58059f647",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.pyfunc.load_model()\n",
    "\n",
    "    What it does: Loads a model from a specified URI in a uniform â€œpyfuncâ€ format that works for inference.\n",
    "    When to use: When you need to load a logged model for making predictions.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbfa0a-0eba-4472-b306-1afb80917ae8",
   "metadata": {},
   "source": [
    "## Custom Python Model\n",
    "\n",
    "======================================================\n",
    "\n",
    "\n",
    "What is it: Most of the times, we require certain preprocessing and/or postprocessing before/after the prediction of the model. The model that mlflow creates for us by default only contains the model itself. If you need to add some pre/postprocessing steps, you can use custom python model to create model pipelines. Please see this link to learn more: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\n",
    "\n",
    "\n",
    "======================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50a657-fce7-4768-a86b-8243370d15c0",
   "metadata": {},
   "source": [
    "Below we apply the concepts above to an example ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350435f4-6f17-4a62-8c3f-11b9e0d08e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:34:36.011824: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ed963e-28d3-48c9-b545-b7062dc13469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a6fd82-0246-466d-b20f-9d76751bdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=os.getenv(\"J_MLFLOW_S3_ENDPOINT_URL\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad33add-5079-4800-ad35-8dad3a29e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name):\n",
    "    \"\"\"\n",
    "    Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "    This function checks if an experiment with the given name exists within MLflow.\n",
    "    If it does, the function returns its ID. If not, it creates a new experiment\n",
    "    with the provided name and returns its ID.\n",
    "\n",
    "    Taken from mlflow.org\n",
    "\n",
    "    Parameters:\n",
    "    - experiment_name (str): Name of the MLflow experiment.\n",
    "\n",
    "    Returns:\n",
    "    - str: ID of the existing or newly created MLflow experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd5dc76c-83eb-45f6-8201-c1e75f486059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_data_path(\n",
    "        s3_client: boto3.client,\n",
    "        bucket_name: str,\n",
    "        base_folder: str = 'preprocessing'\n",
    ") -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Find the latest timestamp folder and NPZ file in the specified bucket/folder\n",
    "    Returns tuple of (full_path, filename)\n",
    "    \"\"\"\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=f\"{base_folder}/\",\n",
    "        Delimiter='/'\n",
    "    )\n",
    "\n",
    "    timestamps = []\n",
    "    for prefix in response.get('CommonPrefixes', []):\n",
    "        folder_name = prefix['Prefix'].strip('/')\n",
    "        try:\n",
    "            timestamp = folder_name.replace(f\"{base_folder}/\", '')\n",
    "            timestamps.append(timestamp)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    if not timestamps:\n",
    "        raise ValueError(\"No timestamp folders found\")\n",
    "\n",
    "    latest_timestamp = sorted(timestamps)[-1]\n",
    "    latest_folder = f\"{base_folder}/{latest_timestamp}\"\n",
    "\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=latest_folder\n",
    "    )\n",
    "\n",
    "    npz_files = [\n",
    "        obj['Key'] for obj in response.get('Contents', [])\n",
    "        if obj['Key'].endswith('.npz')\n",
    "    ]\n",
    "\n",
    "    if not npz_files:\n",
    "        raise ValueError(f\"No NPZ files found in {latest_folder}\")\n",
    "\n",
    "    latest_file = npz_files[0]\n",
    "    return latest_file, latest_file.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a22f2f8-268f-4725-b84c-dd17713313f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_store():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "    X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "    local_path = f\"/tmp/mnist_processed_{timestamp}.npz\"\n",
    "    np.savez_compressed(local_path,\n",
    "                        X_train=X_train, y_train=y_train,\n",
    "                        X_test=X_test, y_test=y_test)\n",
    "\n",
    "    bucket_name = \"mnist-data\"\n",
    "    object_path = f\"preprocessing/{timestamp}/mnist_processed.npz\"\n",
    "\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket_name)\n",
    "    except NameError:\n",
    "        print(f\"Bucket: {bucket_name} does not exist, creating one now!\")\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "    s3.upload_file(local_path, bucket_name, object_path)\n",
    "\n",
    "    os.remove(local_path)\n",
    "    print(f\"Preprocessed data stored to MinIO: {object_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2adc638e-7ad5-4774-99db-482213c59af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "    \n",
    "    bucket_name=\"mnist-data\"\n",
    "    base_folder=\"preprocessing\"\n",
    "    s3_path, filename = get_latest_data_path(s3, bucket_name=bucket_name,\n",
    "                                             base_folder=base_folder)\n",
    "    local_path = \"/tmp\"\n",
    "    local_file = f\"{local_path}/{filename}\"\n",
    "    s3.download_file(bucket_name, s3_path, local_file)\n",
    "\n",
    "    data = np.load(local_file)\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "    X_test, y_test = data['X_test'], data['y_test']\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    mlflow.set_tracking_uri(os.getenv(\"J_MLFLOW_SERVER_URI\"))\n",
    "    experiment_id=get_or_create_experiment(\"MNIST_Hyperparameter_Search_autolog\")\n",
    "    mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    HYPERPARAM_GRID = {\n",
    "        'epochs': [1, 2]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*HYPERPARAM_GRID.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in\n",
    "                          itertools.product(*values)]\n",
    "    \n",
    "    mlflow.autolog()\n",
    "    with mlflow.start_run(run_name=\"mnist-hyperparameter-tuning-parent\"):\n",
    "        for params in param_combinations:\n",
    "            with mlflow.start_run(nested=True):\n",
    "                model = keras.Sequential([\n",
    "                    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "                    keras.layers.MaxPooling2D((2, 2)),\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(128, activation='relu'),\n",
    "                    keras.layers.Dense(10, activation='softmax')\n",
    "                ])\n",
    "        \n",
    "                optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                history = model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    validation_data=(X_test, y_test),\n",
    "                )\n",
    "    \n",
    "                val_acc = history.history['val_accuracy'][-1]\n",
    "    \n",
    "                if val_acc > best_accuracy:\n",
    "                    best_accuracy = val_acc\n",
    "                    best_model = model\n",
    "                    best_params = params\n",
    "                    \n",
    "            if best_model is not None:\n",
    "                artifact_path = \"mnist_model_autolog\"\n",
    "                mlflow.tensorflow.log_model(model, artifact_path)\n",
    "        \n",
    "                model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "                print(\"Model stored at \", model_uri)\n",
    "                print(\"Best Params \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9ef840-facd-432a-9ca6-92756fa03929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data stored to MinIO: preprocessing/20250211-153556/mnist_processed.npz\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec76cbc7-7d81-4cc9-bd8f-08816a99b0a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:9000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = os.getenv(\"J_MLFLOW_S3_ENDPOINT_URL\")\n",
    "os.getenv(\"MLFLOW_S3_ENDPOINT_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e2c5991-6c3d-4649-833c-91289db9e983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/11 15:36:07 INFO mlflow.bedrock: Enabled auto-tracing for Bedrock. Note that MLflow can only trace boto3 service clients that are created after this call. If you have already created one, please recreate the client by calling `boto3.client`.\n",
      "2025/02/11 15:36:07 INFO mlflow.tracking.fluent: Autologging successfully enabled for boto3.\n",
      "2025/02/11 15:36:07 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/02/11 15:36:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/02/11 15:36:08 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "/home/yogesh/miniforge3/envs/mlops/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9116 - loss: 0.2991 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.9116 - loss: 0.2990 - val_accuracy: 0.9809 - val_loss: 0.0588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/11 15:36:30 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run beautiful-shrike-382 at: http://localhost:5000/#/experiments/1/runs/be9d32fc4943459b97cfc47bd616cb7b\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/11 15:36:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stored at  s3://mlflow/1/2b0154bbb08246f4810b67f4992cfbf0/artifacts/mnist_model_autolog\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1872/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9130 - loss: 0.2876 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9131 - loss: 0.2873 - val_accuracy: 0.9783 - val_loss: 0.0638\n",
      "Epoch 2/2\n",
      "\u001b[1m1874/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0521 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9844 - loss: 0.0521 - val_accuracy: 0.9863 - val_loss: 0.0439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/11 15:37:08 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run upset-zebra-240 at: http://localhost:5000/#/experiments/1/runs/baa90d4a50204344b9e821b3c46328b4\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/11 15:37:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stored at  s3://mlflow/1/2b0154bbb08246f4810b67f4992cfbf0/artifacts/mnist_model_autolog\n",
      "ğŸƒ View run mnist-hyperparameter-tuning-parent at: http://localhost:5000/#/experiments/1/runs/2b0154bbb08246f4810b67f4992cfbf0\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "train_mnist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
